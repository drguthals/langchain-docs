---
title: Graph API overview
sidebarTitle: Graph API
---

## Graphs

The `StateGraph` class is the core of LangGraph. It allows you to build **cyclic** and **stateful** workflows, which are essential for creating Agentic AI that needs to loop, reason, and maintain memory over time.

Think of the Graph API as a blueprint. You define your workers (**Nodes**), how data moves between them (**Edges**), and the shared memory they all access (**State**).

## Quick Start: Building an Email Triager
Let's build a "Corporate Email Triager" agent to understand the basics. It will take an incoming email, classify it, and route it to the appropriate handler.

This is an example just using some simple code, but you can find a runnable version of this code (that uses an LLM) in [this repo](https://github.com/drguthals/langchain-graphapi).

```python
from typing import TypedDict, Literal
from langgraph.graph import StateGraph, START, END

# 1. Define the State
class AgentState(TypedDict):
    email_text: str      # Input
    category: str        # Populated by Classifier
    draft_response: str  # Populated by Responder nodes

# 2. Define Nodes (Workers)
def classify_email(state: AgentState):
    # In a real app, this would use an LLM
    if "refund" in state["email_text"]:
        return {"category": "sales"}
    return {"category": "support"}

def handle_sales(state: AgentState):
    return {"draft_response": "Please visit our sales portal."}

def handle_support(state: AgentState):
    return {"draft_response": "Have you tried restarting?"}

# 3. Define Routing Logic
def route_email(state: AgentState) -> Literal["sales", "support"]:
    if state["category"] == "sales":
        return "sales"
    return "support"

# 4. Build the Graph
builder = StateGraph(AgentState)

builder.add_node("classifier", classify_email)
builder.add_node("sales", handle_sales)
builder.add_node("support", handle_support)

builder.add_edge(START, "classifier")
builder.add_conditional_edges("classifier", route_email)
builder.add_edge("sales", END)
builder.add_edge("support", END)

# 5. Compile & Run
graph = builder.compile()
print(graph.invoke({"email_text": "I need a refund"}))
```

## 1. State Management
The `State` is the shared memory of your graph. It determines what data nodes can read and write. The data structured can be any type, but it is typically defined using a shared state schema.

### Schema Definition
You typically define state using a [`TypedDict`](https://docs.python.org/3/library/typing.html#typing.TypedDict) or Pydantic[`BaseModel`](/oss/langgraph/use-graph-api#use-pydantic-models-for-graph-state), if you want recursive data validation (though note that Pydantic is less performant than a `TypedDict` or `dataclass`).
- **TypedDict**: Best for performance and flexibility.
- **Pydantic**: Best if you need validation (e.g., ensuring a field is always a valid email address).

### Input and Output Schemas
By default, the graph will have the same input and output schemas. If you want to change this, you can also specify explicit input and output schemas directly. This is useful when you have a lot of keys, and some are explicitly for input and others for output. See the [guide](/oss/langgraph/use-graph-api#define-input-and-output-schemas) for more information.

### Reducers (Managing Updates)
By default, if a node returns `{"key": "new_value"}`, it **overwrites** the existing value. To change this behavior (e.g., to append items), use Annotated with a reducer function.

```python
import operator
from typing import Annotated

class AdvancedState(TypedDict):
    # Default: Overwrite
    status: str
    
    # Reducer: Append new values to the list
    logs: Annotated[list[str], operator.add]
```

### `MessagesState`
Since managing a list of chat messages is so common, LangGraph provides a pre-built state class. It uses the `add_messages` reducer, which handles appending new messages and updating existing ones by ID. Learn more about [advanced messaging below](#messages-and-messagesstate).

```python
from langgraph.graph import MessagesState

# Inherit from MessagesState to get the 'messages' key automatically
class AgentState(MessagesState):
    custom_field: str
```

## 2. Nodes
Nodes are standard Python functions. They represent a unit of work (like an LLM call, a database query, or an API request). They receive the current state as input, perform some computation or side-effect, and return an updated state.

## Function Signatures
Nodes can accept different arguments depending on what they need:
- **Standard**: `def node(state: State)`
- **With Config**: `def node(state: State, config: RunnableConfig)`
  - Useful for accessing `thread_id` or passing parameters at runtime.
- **With Runtime**: `def node(state: State, runtime: Runtime)`
  - Advanced usage for accessing store and context.

### The `START` and `END` Nodes

- `START`: Represents the entry point. You must connect this to your first node.
- `END`: Represents the termination of a path. When a workflow hits this, it stops.

### Node Caching
You can cache the results of expensive nodes (like large LLM calls) so they don't re-run if the inputs haven't changed.

```python
from langgraph.types import CachePolicy

# Cache this node's output for 60 seconds
builder.add_node("classifier", classify_email, cache_policy=CachePolicy(ttl=60))
```

### Understanding how Nodes are Defined

In LangGraph, nodes are Python functions (either synchronous or asynchronous) that accept the following arguments:

1. `state` – The [state](#state) of the graph
2. `config` – A @[`RunnableConfig`] object that contains configuration information like `thread_id` and tracing information like `tags`
3. `runtime` – A `Runtime` object that contains runtime `context` and other information like `store` and `stream_writer`

Nodes are wrapped into LangChain runnables to support batching, async execution, and tracing.

If you add a node to a graph without specifying a name, it will be given a default name equivalent to the function name.

## 3. Edges & Control Flow
Edges define the logic of your application. They tell the graph "where to go next."

### Normal Edges
Hard-coded transitions. "After A, always go to B."

```python
builder.add_edge("node_a", "node_b")
```

### Conditional Edges
Dynamic transitions based on state. "If category is 'sales', go to B; otherwise go to C."

```python
builder.add_conditional_edges(
    "classifier",      # Source node
    route_email,       # Function determining the next step
    # Optional dictionary mapping function output -> node names
    {"sales": "sales_node", "support": "support_node"} 
)
```

### `Command` (Combined Update & Routing)
Sometimes you want a node to decide internally where to go next, rather than writing a separate routing function. You can return a Command object to update the state and route simultaneously.

```python
from langgraph.types import Command

def classifier(state: AgentState) -> Command[Literal["sales", "support"]]:
    return Command(
        update={"category": "sales"}, # Update state
        goto="sales"                  # Route immediately
    )
```

<Note>
When returning @[`Command`] in your node functions, you must add return type annotations with the list of node names the node is routing to, e.g. `Command[Literal["my_other_node"]]`. This is necessary for the graph rendering and tells LangGraph that `my_node` can navigate to `my_other_node`.
</Note>

Check out this [how-to guide](/oss/langgraph/use-graph-api#combine-control-flow-and-state-updates-with-command) for an end-to-end example of how to use @[`Command`].

#### When should I use Command instead of conditional edges?

- Use @[`Command`] when you need to **both** update the graph state **and** route to a different node. For example, when implementing [multi-agent handoffs](/oss/langchain/multi-agent#handoffs) where it's important to route to a different agent and pass some information to that agent.
- Use [conditional edges](#conditional-edges) to route between nodes conditionally without updating the state.

#### Navigating to a node in a parent graph

If you are using [subgraphs](/oss/langgraph/use-subgraphs), you might want to navigate from a node within a subgraph to a different subgraph (i.e. a different node in the parent graph). To do so, you can specify `graph=Command.PARENT` in @[`Command`]:

```python
def my_node(state: State) -> Command[Literal["other_subgraph"]]:
    return Command(
        update={"foo": "bar"},
        goto="other_subgraph",  # where `other_subgraph` is a node in the parent graph
        graph=Command.PARENT
    )
```

<Note>

Setting `graph` to `Command.PARENT` will navigate to the closest parent graph.

When you send updates from a subgraph node to a parent graph node for a key that's shared by both parent and subgraph [state schemas](#schema), you **must** define a [reducer](#reducers) for the key you're updating in the parent graph state. See this [example](/oss/langgraph/use-graph-api#navigate-to-a-node-in-a-parent-graph).

</Note>

This is particularly useful when implementing [multi-agent handoffs](/oss/langchain/multi-agent#handoffs).

Check out [this guide](/oss/langgraph/use-graph-api#navigate-to-a-node-in-a-parent-graph) for detail.

### `Send` (Map-Reduce / Parallelism)
Standard edges route to one or more nodes with the shared state. Send allows you to route to a node multiple times with different states (e.g., processing 5 emails in parallel).
```python
from langgraph.types import Send

def distribute_work(state):
    # Spawns 3 parallel versions of 'process_item_node'
    return [Send("process_item_node", {"item": i}) for i in state["items"]]

builder.add_conditional_edges("distributor", distribute_work)
```

## 4. Compilation
Before you can run a graph, you must compile it. This step validates your graph structure (checking for orphaned nodes or invalid edges).
```python
# Standard compilation
graph = builder.compile()

# Compilation with Persistence (Memory)
from langgraph.checkpoint.memory import MemorySaver
checkpointer = MemorySaver()

graph = builder.compile(checkpointer=checkpointer)
```

<Warning>
    You **MUST** compile your graph before you can use it.
</Warning>

### Compile Runtime Args
Compiling provides a few basic checks on the structure of your graph (no orphaned nodes, etc). It is also where you can specify runtime args like [checkpointers](/oss/langgraph/persistence) and breakpoints.

## Messages and `MessagesState`
Most modern LLM applications need to store conversation history (a list of HumanMessage and AIMessage objects). LangGraph provides specialized tools to manage this state efficiently.

### The `add_messages` Reducer
In a standard `TypedDict` state, returning a value **overwrites** the existing data. This is bad for chat history because with chats, you want to **append** new messages, not delete the old ones.

While you could use `operator.add` to simply append lists, this causes issues with **Human-in-the-Loop** workflows. If a user manually edits a message in the history, `operator.add` would append the edited version as a new message rather than updating the old one.

To solve this, LangGraph provides the `add_messages` reducer.
- **Appends** new messages to the history.
- **Updates** existing messages if the IDs match (perfect for corrections).
- **Deserializes** inputs (converts Python dicts into LangChain Message objects).

```python
from typing import TypedDict, Annotated
from langchain_core.messages import AnyMessage
from langgraph.graph.message import add_messages

class GraphState(TypedDict):
    # Apply the reducer to the 'messages' key
    messages: Annotated[list[AnyMessage], add_messages]
```

### Serialization & Access
Because `add_messages` handles deserialization automatically, you can send updates to the graph using either objects or raw dictionaries.

```python
# Both of these are valid updates:
return {"messages": [HumanMessage(content="Hello")]}
return {"messages": [{"role": "user", "content": "Hello"}]}
```

<Note>
Since the state is always converted to LangChain objects, you should access message content using dot notation (e.g., `state["messages"][-1].content)` rather than dictionary keys.
</Note>

### The `MessagesState` Shortcut
Since having a list of messages is the most common pattern in LangGraph, you don't always need to define the `TypedDict` and `Annotated` reducer manually.

You can simply inherit from `MessagesState`. This comes with the `messages` key and `add_messages` logic pre-configured.

```python
from langgraph.graph import MessagesState

# Inherit from MessagesState to get 'messages' automatically
class State(MessagesState):
    # Add your own custom fields alongside it
    documents: list[str]
    current_step: str
```

## Graph Control & Operations

### Runtime Configuration (Context)
Sometimes you need to pass dependencies to your nodes that aren't part of the graph's dynamic state, like database connections, user IDs, or model selection flags. You can use `context_schema` for this.

Unlike `State`, which evolves during execution, `Context` is read-only configuration passed at runtime.

```python
from dataclasses import dataclass
from langgraph.runtime import Runtime

# 1. Define the configuration schema
@dataclass
class ContextSchema:
    llm_provider: str = "openai"

# 2. Initialize graph with this schema
graph = StateGraph(State, context_schema=ContextSchema)

# 3. Access context inside a node
def node_a(state: State, runtime: Runtime[ContextSchema]):
    # Access the config passed at runtime
    provider = runtime.context.llm_provider
    # ... logic using specific provider ...

# 4. Pass the context when invoking
graph.invoke(inputs, context={"llm_provider": "anthropic"})
```

### Recursion Limits & Safety
To prevent infinite loops, LangGraph enforces a maximum number of steps (default: 25) per execution. Once this limit is reached, a `GraphRecursionError` is raised.

You can adjust this limit at runtime via the configuration dictionary:

```python
# Increase limit to 50 steps
graph.invoke(inputs, config={"recursion_limit": 50})
```

You can handle recursion limits in two ways:
- **Reactively**: Wrap your invoke in a `try/except` block to catch the `GraphRecursionError`.
- **Proactively**: Access the current step count via `config["metadata"]["langgraph_step"]` inside your nodes. This allows you to detect when you are approaching the limit and route to a fallback strategy (graceful degradation) before the error occurs.

For detailed patterns on implementing proactive monitoring and graceful degradation, see the Recursion Limits Guide.

### Human-in-the-Loop & Interrupts
LangGraph allows you to pause execution using `interrupt()`, wait for user input, and then resume. The `Command` object is the mechanism used to supply this input back to the graph. Check out the [conceptual guide](https://docs.langchain.com/oss/python/langgraph/interrupts) for more information.

To resume a thread that is paused on an interrupt:

```python
# Resume execution by supplying the user input
graph.invoke(Command(resume="User approved the draft"))
```

### Updating State from Tools
In complex agents, tools often need to update the graph state directly (e.g., a "User Lookup" tool that populates customer details in the state). You can do this by returning specific artifacts from your tool execution. See the [Using Inside Tools guide](https://docs.langchain.com/oss/python/langgraph/use-graph-api#use-inside-tools) for implementation details.

### Graph Migrations
When running agents in production, you will eventually need to update your code (add nodes, change logic) while existing threads are still active. LangGraph handles migrations gracefully with specific compatibility guarantees:
- **Active Threads (Not Interrupted)**: You can generally modify topology for new executions, but persisted or interrupted threads impose stricter compatibility constraints depending on the checkpointer backend.
- **Interrupted Threads**: You can make most topology changes, but avoid renaming or removing nodes that the thread is currently paused on or about to enter.
- State Schema:
    - *Safe*: Adding new keys or removing unused keys.
    *Unsafe*: Renaming keys (saved data will be lost) or changing data types in incompatible ways (may cause crashes when loading old state).

### Visualization
As graphs grow in complexity, visualizing the flow becomes critical for debugging. LangGraph supports generating diagrams directly from your compiled graph code.

See the [Visualization Guide](https://docs.langchain.com/oss/python/langgraph/use-graph-api#visualize-your-graph) for how to generate Mermaid diagrams or ASCII charts.
